
# AUTISM_DISORDER_ANALYSIS__USING_MULTI_TASK_CASCADED_CONVOLUTIONAL_NEURAL_NETWORK___KERAS__AND__TENSORFLOW_final.ipynb

# Automatically generated by Colaboratory.

pip install mtcnn

pip install tensorflow

pip install keras

import mtcnn                                                                                                      # Mtcnn,pretrained model specialised for detecting face from image
import numpy as np                                                                                                # Here numpy will be used for storing records of 'fer2013.csv' dataset in numpy array format
import tensorflow as tf                                                                                           # Tensorflow will be used for starting session for emotion analysis graph
import keras                                                                                                      # Keras is an open-source neural-network library 
from keras.models import Sequential                                                                               # Sequential model will be used for creating input and convolutional neural networks
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D                                                   # These layers will be used for extracting features and reducing resolution to extract features more deeply
from keras.layers import Dense, Activation, Dropout, Flatten                                                      # These layers will be used to prevent overfitting and in making of fully connected layers 
from keras.preprocessing import image                                                                             # We import image library for processing image
from keras.preprocessing.image import ImageDataGenerator                                                          # ImageDataGenerator will be used to generate image from pixel values from 'fer2013.csv' dataset
import matplotlib.pyplot as plt                                                                                   # We will use pyplot for creating graph and labelling it as 'plt'
from matplotlib import pyplot
from matplotlib.patches import Rectangle                                                                          # We use Rectangle to create window boundary around face detected in image
from matplotlib.patches import Circle                                                                             # We use Circle to mark keypoints like left eye,right eye,nose and mouth on the face
from mtcnn.mtcnn import MTCNN                                                                                     # Multi Task Cascaded Convolutional Neural network,deep learning model will be used for identifying 
                                                                                                                  # the coordinates of face and keypoints




from google.colab import drive                                                                                    # We import drive from google to use dataset and image
drive.mount('/content/drive')                                                                                     # Mounting drive to use files while inputting




!unzip -uq "/content/drive/My Drive/ZIPPED FILE/fer2013.zip" -d "/content/drive/My Drive/UNZIPPED FILE"           #Unzipping the zip file of fer2013.zip into UNZIPPED FILE folder
!unzip -uq "/content/drive/My Drive/ZIPPED FILE/dif1.zip" -d "/content/drive/My Drive/UNZIPPED FILE"              #Unzipping the zip file of dif1.zip into UNZIPPED FILE folder
!unzip -uq "/content/drive/My Drive/ZIPPED FILE/different.zip" -d "/content/drive/My Drive/UNZIPPED FILE"         #Unzipping the zip file of different.zip into UNZIPPED FILE folder

config=tf.ConfigProto(device_count={'GPU':0,'CPU':56})                                                            # We will use CPU for this project and start a session for graph 
SESS=tf.Session(config=config)
keras.backend.set_session(SESS)

num_classes=7                                                                                                     # We have 7 emotions ,so we define classes equal to 7
batch_size=256                                                                                                    # At one at a time we will sample 256 instances in convolutional neural network 
epochs=50                                                                                                         # Training will be done for 20 epochs
filename0='/content/drive/My Drive/UNZIPPED FILE/dif1.jpg'                                                        # Giving the link of input image 'dif1.jpg' to 'filename0'
filename1='/content/drive/My Drive/UNZIPPED FILE/different.jpg'                                                   # Giving the link of input image 'different.jpg' to 'filename1'
pixels0=pyplot.imread(filename0)                                                                                  # Reading the pixels values of input image from filename0
pixels1=pyplot.imread(filename1)                                                                                  # Reading the pixels values of input image from filename1
detector=MTCNN()                                                                                                  # Defining  MTCNN() model
FACES0=detector.detect_faces(pixels0)                                                                             # Detecting faces from input image from 'pixels0'
FACES1=detector.detect_faces(pixels1)                                                                             # Detecting faces from input image from 'pixels1'

for face0 in FACES0:                                                                                              # Printing the coordinates  and features or keypoints of each face in input image 'dif1.jpg' 
  print(face0)

for face1 in FACES1:                                                                                              # Printing the coordinates  and features or keypoints of each face in input image 'different.jpg' 
  print(face1)



with open('/content/drive/My Drive/UNZIPPED FILE/fer2013.csv') as f:                                              # Opening the 'fer2013.csv' file
  content=f.readlines()                                                                                           # Reading the rows of dataset
  lines=np.array(content)                                                                                         # Converting instances into numpy arrays

  number_of_instances=lines.size                                                                                  # Counting the total number of rows in dataset 

print("Number of instances in the fer2013 dataset =",number_of_instances)                                         # Printing  total number of rows

print("Instance length of fer2013 dataset =",len(lines[1].split(",")[1].split(" ")))                              # Printing the length of a single row of dataset fer2013



def draw_image_with_boxes(filename, result_list):
	              
	data = pyplot.imread(filename)                                          				  # We load the image  from filename

	pyplot.imshow(data)                                            	        				  # Plot the image

	ax = pyplot.gca()                                                       				  # Get the context for drawing boxes

	for result in result_list:                                              				  # Plot each box
		
		x, y, width, height = result['box']		                                		  # Get coordinates

		rect = Rectangle((x, y), width, height, fill=False, color='red')      				  # Create the shape
		
		ax.add_patch(rect)                                                    				  # Draw the box

		for key, value in result['keypoints'].items():                        				  # Draw the dots
			
			dot = Circle(value, radius=2, color='red')                          			  # Create and draw dot
			ax.add_patch(dot)


	pyplot.show()                                                           				  # Show the plot

def draw_faces(filename, result_list):
	
	data = pyplot.imread(filename)	                                                                          # We load the image  from filename																												# We load the image  from filename
	
	for i in range(len(result_list)):                                                                         # Plot each face as a subplot																												# plot each face as a subplot
		
		x1,y1, width, height = result_list[i]['box']                                                      # Get coordinates																				      
		
		x2, y2 = (x1 + width), (y1 + height)
		
		pyplot.subplot(1, len(result_list), i+1)	                                                  # Define subplot																						 define subplot
		pyplot.axis('off')
		
		pyplot.imshow(data[y1:y2, x1:x2])                                                                 # Plot face
	
	pyplot.show()                                                                                             # Show the plot     																																	# show the plot



def emotion_analysis(emotions):                                                                                   # Creating a function emotion_analysis for plotting graph for analyzing emotions
   
    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')                                 # Declaring  emotion  labels as objects
    
    y_pos = np.arange(len(objects))                                                                               # Storing the total number of object labels
    
    plt.bar(y_pos, emotions, align='center', alpha=0.5)                                                           # Plotting the bar with respect to "y_pos" and  "emotions"
    plt.xticks(y_pos, objects)                                                                                    # Plotting emotion labels on X-axis
    plt.ylabel('percentage')                                                                                      # Plotting the label "percentage" along Y-axis 
    plt.title('emotion')                                                                                          # Plotting the label "emotion" along X-axis
    
    plt.show()                                                                                                    # Displaying the final resulting graph



def EMOTION_ANALYSIS(img):                                                                                        # Defining a function "EMOTION_ANALYSIS"  for displaying the required result for given input image variable "img"     
  
  x = image.img_to_array(img)                                                                                     # Storing pixel values in image array format
  x = np.expand_dims(x, axis = 0)                                                                                 # Expanding the dimension of input image by 1

  x /= 255                                                                                                        # Normalize inputs between [0, 1] in  "x"

  custom = model.predict(x)                                                                                       # Predicting the outcome using "model"
  emotion_analysis(custom[0])


  x = np.array(x, 'float32')                                                                                      # Converting all the  values datatype from integer to float in "x_train" and converting it into numpy array        
  x = x.reshape([48, 48])                                                                                         # Reshaping the image dimensions to (48,48,1)



plt.show()                                                                                                        # Show the plot
    



draw_image_with_boxes(filename0, FACES0)                                                                          # We display the required result of detecting face and keypoints in image
draw_faces(filename0,FACES0)

draw_image_with_boxes(filename1, FACES1)                                                                          # We display the required result of detecting face and keypoints in image
draw_faces(filename1,FACES1)



x_train, y_train, x_test, y_test = [], [], [], []                                                                 # Defining four lists for X train, Y train, X test and Y test 

for i in range(1,number_of_instances):                                                                            # Traversing all the instances in dataset "fer2013.csv"
    try:
        emotion, img, usage = lines[i].split(",")                                                                 # We store each row value of each column in variables "emotion" ,"img" ,"usage"
                                                                                                                  # That is label numbers in "emotion", pixel values of image in "img" and usage labels in"usage"

        val = img.split(" ")                                                                                      # Storing pixel values seperated by space i.e. " "
            
        pixels = np.array(val, 'float32')                                                                         # Converting all pixel values datatype from integer to float and storing in numpy array
        
        emotion = keras.utils.to_categorical(emotion, num_classes)                                                # Defining the number of emotion classes
    
        if 'Training' in usage:                                                                                   # If the instance has the usage label "Training" then we append values of such instance in training lists
            y_train.append(emotion)
            x_train.append(pixels)
        elif 'PublicTest' in usage:                                                                               # If the instance has the usage label "PublicTest" then we append values of such instance in testing lists
            y_test.append(emotion)
            x_test.append(pixels)
    except:
	    print("",end="")
     
print("X train total image pixel values",len(x_train))                                                            # Displaying the total number of image pixel values in "x_train"
print("Y train total image pixel values",len(y_train))                                                            # Displaying the total number of image pixel values in "y_train"
print("X test total image pixel values",len(x_test))                                                              # Displaying the total number of image pixel values in "x_test"
print("Y test total image pixel values",len(y_test))                                                              # Displaying the total number of image pixel values in "y_test"

x_train = np.array(x_train, 'float32')                                                                            # Converting all the  values datatype from integer to float in "x_train" and converting it into numpy array    
y_train = np.array(y_train, 'float32')                                                                            # Converting all the  values datatype from integer to float in "y_train" and converting it into numpy array  
x_test = np.array(x_test, 'float32')                                                                              # Converting all the  values datatype from integer to float in "x_test" and converting it into numpy array  
y_test = np.array(y_test, 'float32')                                                                              # Converting all the  values datatype from integer to float in "y_test" and converting it into numpy array  

x_train /= 255                                                                                                    # Normalize inputs between [0, 1] in "x_train"
x_test /= 255                                                                                                     # Normalize inputs between [0, 1] in "x_test"

x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)                                                            # Reshaping the image dimensions to (48,48,1) for inputting in Convolutional Neural Network layers 
x_train = x_train.astype('float32')                                                                               # Defining its datatype as float
x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)                                                               # Reshaping the image dimensions to (48,48,1) for inputting in Convolutional Neural Network layers 
x_test = x_test.astype('float32')                                                                                 # Defining its datatype as float

print(x_train.shape[0], 'train samples')                                                                          # Displaying the total number of samples used for training
print(x_test.shape[0], 'test samples')                                                                            # Displaying the total number of samples used for testing

model = Sequential()                                                                                              # Defining a Convolutional Neural Network model

                                                                            
model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))                                           # First Convolutional Neural Network layer
model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))


model.add(Conv2D(64, (3, 3), activation='relu'))                                                                  # Second  Convolutional Neural Network layer
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))


model.add(Conv2D(128, (3, 3), activation='relu'))                                                                 # Third  Convolutional Neural Network layer
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))


model.add(Flatten())                                                                                              # Creating a flattening layer 


model.add(Dense(1024, activation='relu'))                                                                         # Fully connected neural networks
model.add(Dropout(0.2))
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(num_classes, activation='softmax'))                                                               # Output layer

gen = ImageDataGenerator()
train_generator = gen.flow(x_train, y_train, batch_size=batch_size)
model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])

fit=True																																																							
if fit == True:
																															 # Train for all trainset
	model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs) 			  # Train for randomly selected one
else:
	model.load_weights('/data/facial_expression_model_weights.h5')                                            # Load weights



score = model.evaluate(x_test, y_test)                                                                            # Overall evaluation
print('Test loss:', score[0])                                                                                     # Displaying validation loss
print('Test accuracy:', 100*score[1])                                                                             # Displaying validation accuracy



img1 = image.load_img("/content/drive/My Drive/UNZIPPED FILE/AUTISM IMAGES/1.jpg",grayscale=True, target_size=(48, 48))         #  Taking input image "1.jpg"
img2 = image.load_img("/content/drive/My Drive/UNZIPPED FILE/AUTISM IMAGES/2.jpg",grayscale=True, target_size=(48, 48))         #  Taking input image "2.jpg"



filename0A='/content/drive/My Drive/UNZIPPED FILE/AUTISM IMAGES/1.jpg'                                            # Giving the link of input image '1.jpg' to 'filename0A'
filename1A='/content/drive/My Drive/UNZIPPED FILE/AUTISM IMAGES/2.jpg'                                            # Giving the link of input image '2.jpg' to 'filename1A'
pixels0A=pyplot.imread(filename0A)                                                                                # Reading the pixels values of input image from filename0A
pixels1A=pyplot.imread(filename1A)                                                                                # Reading the pixels values of input image from filename1A
detector=MTCNN()                                                                                                  # Defining  MTCNN() model
FACES0A=detector.detect_faces(pixels0A)                                                                           # Detecting faces from input image from 'pixels0'
FACES1A=detector.detect_faces(pixels1A)




print(draw_faces(filename0A, FACES0A),EMOTION_ANALYSIS(img1),draw_faces(filename1A, FACES1A),EMOTION_ANALYSIS(img2))   # Displaying the overall final result of this program



  
